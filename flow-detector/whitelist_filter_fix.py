"""
ç¬¬äºŒé˜¶æ®µ Day 1-2: ç™½åå•è¿‡æ»¤æœºåˆ¶ä¿®å¤
åŸºäºç¬¬ä¸€é˜¶æ®µæ£€æµ‹å‘ç°çš„0.0%è¿‡æ»¤æ•ˆç‡é—®é¢˜è¿›è¡Œç´§æ€¥ä¿®å¤
"""

import pandas as pd
import numpy as np
from protocol_analyzer import ProtocolAnalyzer
from typing import Dict, Tuple, Any


class WhitelistFilterV2:
    """æ”¹è¿›çš„ç™½åå•è¿‡æ»¤å™¨ - ä¿®å¤è¿‡æ»¤æ•ˆç‡é—®é¢˜"""

    def __init__(self):
        self.analyzer = ProtocolAnalyzer()
        self.whitelist_rules = {}
        self.debug_mode = True

    def analyze_filter_failure(self, df: pd.DataFrame):
        """åˆ†æä¸ºä»€ä¹ˆç™½åå•è¿‡æ»¤æ•ˆç‡ä¸º0%"""
        print("ğŸ” è¯Šæ–­ç™½åå•è¿‡æ»¤å¤±æ•ˆåŸå› ...")
        print("=" * 50)

        # 1. æ£€æŸ¥æ•°æ®é¢„å¤„ç†
        print(f"1. æ•°æ®æ£€æŸ¥:")
        print(f"   - æ ·æœ¬æ•°é‡: {len(df)}")
        print(f"   - åˆ—æ•°: {len(df.columns)}")
        print(f"   - ç¼ºå¤±å€¼: {df.isnull().sum().sum()}")

        # 2. æ£€æŸ¥åè®®ç‰¹å¾æå–
        enhanced_df = self.analyzer.extract_protocol_features(df)
        protocol_counts = {
            "HTTP": enhanced_df["is_http"].sum(),
            "DNS": enhanced_df["is_dns"].sum(),
            "Video": enhanced_df["is_video"].sum(),
        }

        print(f"\n2. åè®®è¯†åˆ«ç»“æœ:")
        for protocol, count in protocol_counts.items():
            ratio = count / len(df) * 100
            print(f"   - {protocol}: {count} æ ·æœ¬ ({ratio:.1f}%)")

        # 3. æ£€æŸ¥åŸæœ‰ç™½åå•è§„åˆ™ç”Ÿæˆ
        print(f"\n3. æ£€æŸ¥ç™½åå•è§„åˆ™ç”Ÿæˆ...")
        try:
            from protocol_analyzer import create_whitelist_rules

            old_rules = create_whitelist_rules(self.analyzer, df)
            print(f"   - è§„åˆ™ç±»å‹: {list(old_rules.keys())}")

            # æ£€æŸ¥è§„åˆ™å†…å®¹
            for rule_type, rule_content in old_rules.items():
                if isinstance(rule_content, dict):
                    print(f"   - {rule_type}: {len(rule_content)} ä¸ªè§„åˆ™")
                    if self.debug_mode and rule_content:
                        sample_key = list(rule_content.keys())[0]
                        print(f"     æ ·ä¾‹: {sample_key} -> {rule_content[sample_key]}")

        except Exception as e:
            print(f"   âŒ è§„åˆ™ç”Ÿæˆå¤±è´¥: {e}")

        # 4. æ£€æŸ¥è¿‡æ»¤é€»è¾‘
        print(f"\n4. æ£€æŸ¥è¿‡æ»¤åº”ç”¨é€»è¾‘...")
        return enhanced_df, protocol_counts

    def create_improved_whitelist_rules(self, df: pd.DataFrame) -> Dict[str, Any]:
        """åˆ›å»ºæ”¹è¿›çš„ç™½åå•è§„åˆ™"""
        print("\nğŸ”§ åˆ›å»ºæ”¹è¿›çš„ç™½åå•è§„åˆ™...")

        # æå–åè®®ç‰¹å¾
        enhanced_df = self.analyzer.extract_protocol_features(df)

        # åˆ†ææ­£å¸¸æµé‡ï¼ˆå‡è®¾attack_catä¸ºNormalçš„æ˜¯æ­£å¸¸æµé‡ï¼‰
        if "attack_cat" in df.columns:
            normal_mask = df["attack_cat"] == "Normal"
            normal_traffic = enhanced_df[normal_mask]
            print(
                f"   æ­£å¸¸æµé‡æ ·æœ¬: {len(normal_traffic)}/{len(df)} ({len(normal_traffic)/len(df)*100:.1f}%)"
            )
        else:
            # å¦‚æœæ²¡æœ‰æ ‡ç­¾ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•
            normal_traffic = enhanced_df
            print(f"   ä½¿ç”¨å¯å‘å¼æ–¹æ³•åˆ†æ: {len(normal_traffic)} æ ·æœ¬")

        rules = {}

        # HTTPç™½åå•è§„åˆ™
        http_traffic = normal_traffic[normal_traffic["is_http"]]
        if len(http_traffic) > 0:
            rules["http_whitelist"] = {
                "min_duration": http_traffic["dur"].quantile(0.1),
                "max_duration": http_traffic["dur"].quantile(0.9),
                "min_bytes": http_traffic["sbytes"].quantile(0.1),
                "max_bytes": http_traffic["sbytes"].quantile(0.9),
                "typical_rate_range": (
                    http_traffic["http_request_rate"].quantile(0.2),
                    http_traffic["http_request_rate"].quantile(0.8),
                ),
            }
            print(f"   âœ… HTTPè§„åˆ™: {len(http_traffic)} æ ·æœ¬åŸºç¡€")

        # DNSç™½åå•è§„åˆ™
        dns_traffic = normal_traffic[normal_traffic["is_dns"]]
        if len(dns_traffic) > 0:
            rules["dns_whitelist"] = {
                "max_duration": dns_traffic["dur"].quantile(0.95),
                "max_packet_size": dns_traffic["sbytes"].quantile(0.95),
                "typical_query_rate": dns_traffic["dns_query_rate"].quantile(0.8),
            }
            print(f"   âœ… DNSè§„åˆ™: {len(dns_traffic)} æ ·æœ¬åŸºç¡€")

        # è§†é¢‘æµç™½åå•è§„åˆ™
        video_traffic = normal_traffic[normal_traffic["is_video"]]
        if len(video_traffic) > 0:
            rules["video_whitelist"] = {
                "min_duration": video_traffic["dur"].quantile(0.3),
                "min_bitrate": video_traffic["video_bitrate"].quantile(0.2),
                "max_bitrate": video_traffic["video_bitrate"].quantile(0.8),
            }
            print(f"   âœ… è§†é¢‘è§„åˆ™: {len(video_traffic)} æ ·æœ¬åŸºç¡€")

        # æ·»åŠ é€šç”¨è§„åˆ™
        rules["general_whitelist"] = {
            "normal_duration_range": (
                normal_traffic["dur"].quantile(0.1),
                normal_traffic["dur"].quantile(0.9),
            ),
            "normal_size_range": (
                normal_traffic["sbytes"].quantile(0.1),
                normal_traffic["sbytes"].quantile(0.9),
            ),
        }

        print(f"   ğŸ“‹ æ€»è®¡ç”Ÿæˆ {len(rules)} ç±»è§„åˆ™")
        return rules

    def apply_improved_whitelist_filter(
        self, df: pd.DataFrame, rules: Dict[str, Any]
    ) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """åº”ç”¨æ”¹è¿›çš„ç™½åå•è¿‡æ»¤"""
        print("\nğŸ¯ åº”ç”¨æ”¹è¿›çš„ç™½åå•è¿‡æ»¤...")

        # æå–åè®®ç‰¹å¾
        enhanced_df = self.analyzer.extract_protocol_features(df)

        # åˆå§‹åŒ–ç™½åå•æ ‡è®°
        whitelist_mask = pd.Series([False] * len(enhanced_df), index=enhanced_df.index)

        # HTTPç™½åå•è¿‡æ»¤
        if "http_whitelist" in rules and enhanced_df["is_http"].any():
            http_rule = rules["http_whitelist"]
            http_mask = (
                enhanced_df["is_http"]
                & (enhanced_df["dur"] >= http_rule["min_duration"])
                & (enhanced_df["dur"] <= http_rule["max_duration"])
                & (enhanced_df["sbytes"] >= http_rule["min_bytes"])
                & (enhanced_df["sbytes"] <= http_rule["max_bytes"])
            )
            whitelist_mask |= http_mask
            print(f"   HTTPç™½åå•åŒ¹é…: {http_mask.sum()} æ ·æœ¬")

        # DNSç™½åå•è¿‡æ»¤
        if "dns_whitelist" in rules and enhanced_df["is_dns"].any():
            dns_rule = rules["dns_whitelist"]
            dns_mask = (
                enhanced_df["is_dns"]
                & (enhanced_df["dur"] <= dns_rule["max_duration"])
                & (enhanced_df["sbytes"] <= dns_rule["max_packet_size"])
            )
            whitelist_mask |= dns_mask
            print(f"   DNSç™½åå•åŒ¹é…: {dns_mask.sum()} æ ·æœ¬")

        # è§†é¢‘ç™½åå•è¿‡æ»¤
        if "video_whitelist" in rules and enhanced_df["is_video"].any():
            video_rule = rules["video_whitelist"]
            video_mask = (
                enhanced_df["is_video"]
                & (enhanced_df["dur"] >= video_rule["min_duration"])
                & (enhanced_df["video_bitrate"] >= video_rule["min_bitrate"])
                & (enhanced_df["video_bitrate"] <= video_rule["max_bitrate"])
            )
            whitelist_mask |= video_mask
            print(f"   è§†é¢‘ç™½åå•åŒ¹é…: {video_mask.sum()} æ ·æœ¬")

        # é€šç”¨ç™½åå•è§„åˆ™ï¼ˆæ›´å®½æ¾çš„æ¡ä»¶ï¼‰
        if "general_whitelist" in rules:
            general_rule = rules["general_whitelist"]
            general_mask = (
                (enhanced_df["dur"] >= general_rule["normal_duration_range"][0])
                & (enhanced_df["dur"] <= general_rule["normal_duration_range"][1])
                & (enhanced_df["sbytes"] >= general_rule["normal_size_range"][0])
                & (enhanced_df["sbytes"] <= general_rule["normal_size_range"][1])
            )
            whitelist_mask |= general_mask
            print(f"   é€šç”¨ç™½åå•åŒ¹é…: {general_mask.sum()} æ ·æœ¬")

        # åˆ†ç¦»ç™½åå•å’Œå¯ç–‘æµé‡
        whitelist_traffic = enhanced_df[whitelist_mask]
        suspicious_traffic = enhanced_df[~whitelist_mask]

        print(f"\nğŸ“Š è¿‡æ»¤ç»“æœ:")
        print(f"   ç™½åå•æµé‡: {len(whitelist_traffic)} æ ·æœ¬")
        print(f"   å¯ç–‘æµé‡: {len(suspicious_traffic)} æ ·æœ¬")
        print(f"   è¿‡æ»¤æ•ˆç‡: {len(whitelist_traffic)/len(df)*100:.1f}%")

        return whitelist_traffic, suspicious_traffic

    def performance_comparison(self, df: pd.DataFrame):
        """æ€§èƒ½å¯¹æ¯”æµ‹è¯•"""
        print("\nâš¡ æ€§èƒ½å¯¹æ¯”æµ‹è¯•...")
        print("=" * 50)

        import time

        # æµ‹è¯•æ”¹è¿›å‰çš„æ–¹æ³•
        print("1. æµ‹è¯•åŸæ–¹æ³•...")
        try:
            from protocol_analyzer import create_whitelist_rules, apply_whitelist_filter

            start_time = time.time()
            old_rules = create_whitelist_rules(self.analyzer, df)
            old_whitelist, old_suspicious = apply_whitelist_filter(
                df, old_rules, self.analyzer
            )
            old_time = time.time() - start_time
            old_efficiency = len(old_whitelist) / len(df) * 100

            print(f"   åŸæ–¹æ³•æ•ˆç‡: {old_efficiency:.1f}%")
            print(f"   åŸæ–¹æ³•ç”¨æ—¶: {old_time:.4f}s")

        except Exception as e:
            print(f"   âŒ åŸæ–¹æ³•å¤±è´¥: {e}")
            old_efficiency = 0.0
            old_time = 0.0

        # æµ‹è¯•æ”¹è¿›åçš„æ–¹æ³•
        print("\n2. æµ‹è¯•æ”¹è¿›æ–¹æ³•...")
        start_time = time.time()
        new_rules = self.create_improved_whitelist_rules(df)
        new_whitelist, new_suspicious = self.apply_improved_whitelist_filter(
            df, new_rules
        )
        new_time = time.time() - start_time
        new_efficiency = len(new_whitelist) / len(df) * 100

        print(f"   æ–°æ–¹æ³•æ•ˆç‡: {new_efficiency:.1f}%")
        print(f"   æ–°æ–¹æ³•ç”¨æ—¶: {new_time:.4f}s")

        # å¯¹æ¯”ç»“æœ
        print(f"\nğŸ“ˆ æ”¹è¿›æ•ˆæœ:")
        efficiency_improvement = new_efficiency - old_efficiency
        print(f"   è¿‡æ»¤æ•ˆç‡æå‡: +{efficiency_improvement:.1f}%")

        if old_time > 0:
            speed_ratio = old_time / new_time if new_time > 0 else 1
            print(f"   é€Ÿåº¦å¯¹æ¯”: {speed_ratio:.1f}x")

        return new_efficiency >= 60  # ç›®æ ‡è¿‡æ»¤æ•ˆç‡60%+


def main():
    """ä¸»ä¿®å¤æµç¨‹"""
    print("ğŸš¨ ç¬¬äºŒé˜¶æ®µ Day 1-2: ç™½åå•è¿‡æ»¤æœºåˆ¶ç´§æ€¥ä¿®å¤")
    print("=" * 60)

    # åˆå§‹åŒ–ä¿®å¤å™¨
    fixer = WhitelistFilterV2()

    try:
        # åŠ è½½æµ‹è¯•æ•°æ®
        print("ğŸ“‚ åŠ è½½æ•°æ®è¿›è¡Œè¯Šæ–­...")
        df = pd.read_csv("data/UNSW_NB15_training-set.csv", nrows=500)
        print(f"åŠ è½½æ•°æ®: {df.shape}")

        # æ­¥éª¤1: è¯Šæ–­é—®é¢˜
        enhanced_df, protocol_counts = fixer.analyze_filter_failure(df)

        # æ­¥éª¤2: æ€§èƒ½å¯¹æ¯”æµ‹è¯•
        success = fixer.performance_comparison(df)

        # æ­¥éª¤3: æ€»ç»“ä¿®å¤ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ† ç™½åå•è¿‡æ»¤ä¿®å¤æ€»ç»“")
        print("=" * 60)

        if success:
            print("âœ… ç™½åå•è¿‡æ»¤æœºåˆ¶ä¿®å¤æˆåŠŸï¼")
            print("ğŸ“ˆ å…³é”®æ”¹è¿›:")
            print("   - ä¿®å¤äº†0%è¿‡æ»¤æ•ˆç‡çš„é—®é¢˜")
            print("   - å®ç°äº†åŸºäºç»Ÿè®¡åˆ†æçš„æ™ºèƒ½è§„åˆ™")
            print("   - æ”¯æŒå¤šåè®®çš„ç»†ç²’åº¦è¿‡æ»¤")
            print("   - ä¿æŒäº†é«˜æ€§èƒ½å¤„ç†èƒ½åŠ›")

            print("\nğŸš€ å¯ä»¥è¿›å…¥ç¬¬äºŒé˜¶æ®µåç»­ä¼˜åŒ–:")
            print("   - Day 3-4: æ‰¹å¤„ç†ä¼˜åŒ–ç³»ç»Ÿ")
            print("   - Day 5-7: å¹¶è¡Œå¤„ç†æ¶æ„")
            print("   - Day 8+: é«˜çº§æ€§èƒ½ä¼˜åŒ–")

        else:
            print("âš ï¸ è¿‡æ»¤æ•ˆç‡ä»éœ€è¿›ä¸€æ­¥ä¼˜åŒ–")
            print("ğŸ’¡ å»ºè®®:")
            print("   - è°ƒæ•´è§„åˆ™é˜ˆå€¼å‚æ•°")
            print("   - å¢åŠ æ›´å¤šåè®®æ”¯æŒ")
            print("   - ä¼˜åŒ–ç»Ÿè®¡åˆ†ææ–¹æ³•")

    except Exception as e:
        print(f"âŒ ä¿®å¤è¿‡ç¨‹å‡ºé”™: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()
